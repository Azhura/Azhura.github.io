---
layout: post
title: Reconocimiento de voz y procesamiento de texto 
---
Convirtiendo Audio Analógico a texto para análisis con **PLN**.

## Contenido
[1.Introducción](#1.Introducción)      
[2.Procesos](#2.Procesos)   
[3.Conclusión](#3.Conclusión)     
[4.Recursos](#4.Recursos)   

## 1.Introducción

El objetivo es extraer información de audios analógicos y transformarlos en texto, procesar la información y efectuar operaciones básicas como traducción de idiomas y análisis semántico de palabras básicas con procesos del lenguaje natural [PLN](https://es.wikipedia.org/wiki/Procesamiento_de_lenguajes_naturales), utilizando las librerías: [speech_recognition](https://pypi.org/project/SpeechRecognition/), [googletrans](https://pypi.org/project/googletrans/), [spacy](https://spacy.io/usage). 

**Acerca de los datos de audio utilizados**  

[Open Speech Repository](http://www.voiptroubleshooter.com/open_speech/index.html) proporciona archivos de voz de uso gratuito en varios idiomas para su uso en pruebas de voz sobre IP y otras aplicaciones. Este repositorio fue desarrollado por [Telchemy](http://www.voiptroubleshooter.com/sponsors/telchemy.html) para facilitar la investigación académica y de la industria en los campos de calidad de voz, códecs de voz, reconocimiento de voz y otras áreas. Para este proyecto utilizo el archivo **"OSR_us_000_0061_8k.wav"** el cual se correspode al idioma de inglés americano compuesto por un solo canal de voz.

**Acerca del preprocesamiento de texto**

Hay algunos tipos de preprocesamiento para mejorar la forma en que modelamos con las palabras. 
El primero es "lemmatizar" una palabra en su forma base. 
Por ejemplo, "tono" es el lema de la palabra "tonos". 

También es común eliminar las palabras de parada conocidas como stopwords. 
Las stopwords son palabras que aparecen frecuentemente en el lenguaje y no contienen mucha información como por ejemplo "el" "de" "en" "si" , etc...

Con un token spacy, token.lemma_ devuelve el lema, mientras que token.is_stop devuelve un booleano Verdadero si el token es una palabra de parada (y Falso en caso contrario).

**palabras clave de identificación**

Los datos lingüísticos tienen mucho ruido mezclado con contenido informativo. 
Eliminar las palabras de parada podría ayudar a centrarse en las palabras más relevantes. 
La lematización ayuda de manera similar al combinar múltiples formas de la misma palabra en una forma base ("calmante", "calma", "calmado" cambiaría a "tranquilo").
Sin embargo, lemmatizar y dejar caer las palabras de parada podría hacer que sus modelos predictivos funcionaran peor, por lo tanto, debe tratar este preprocesamiento como parte de su proceso de optimización de hiperparámetros.

## 2.Procesos

**2.1 Carga de librerías**


```python
# Librerías
import speech_recognition as sr # Reconocimiento de voz
import googletrans as go # traducción de texto con google
import spacy as sp # Procesado y etiquetado de palabras
nlp_en = sp.load('en') # Modelo PLN en su version Inglesa
nlp_es = sp.load('es') # Modelo PLN en su version español
print("Librerías cargadas")
```

    Librerías cargadas
    

**2.2 Creación de variables**


```python
# Creación de las variables
traduccion = go.Translator() # Constructor para la traducción
r = sr.Recognizer() # Constructor para el reconocimiento de voz
harvard = sr.AudioFile('OSR_us_000_0061_8k.wav') # Carga del archivo de audio 
print("Variables Cargadas" , harvard)
```

    Variables Cargadas <speech_recognition.AudioFile object at 0x000002452D4CEB70>
    

**2.3 Extracción y procesado de la información**


```python
with harvard as source:
    audio = r.record(source) # Reconocimiento de voz
    text = r.recognize_google(audio) # Pasando a texto plano
    doc_en = nlp_en(text) # Algoritmo NPL
    doc_es = traduccion.translate(text,dest='es') # traductor
print("Proceso completo")    
```

    Proceso completo
    

**2.4a Resultado**   
Podemos verificar la extracción y la adaptación de la información para ser analizada más a fondo.
Si queremos verificar que tan bien a sido nuestra extracción del audio podemos comparar desde la [lista 30](http://www.cs.columbia.edu/~hgs/audio/harvard.html) que se compone de 10 oraciones.   
Debajo tendremos 3 columnas indicando la tokenización de cada palabra , seguida del lemma y sus stopword´s.


```python
print("English \n")
print(doc_en,"\n")
print(f"Token \t\tLemma \t\tStopword".format('Token', 'Lemma', 'Stopword'))
print("-"*40)
for token in doc_en:
    print(f"{str(token)}\t\t{token.lemma_}\t\t{token.is_stop}")
```

    English 
    
    the mute muffled the high tones of the horn the gold ring fits only a pierced-ear the old pan was covered with hard fudge what's the log float in the wide river the node on the stalk of wheat grew daily the Heap of fallen leaves was set on fire right fast if you want to finish early his shirt was clean but one button was gone the barrel of beer was a brew of malt and hops tin cans are absent from store shelves 
    
    Token 		Lemma 		Stopword
    ----------------------------------------
    the		the		True
    mute		mute		False
    muffled		muffle		False
    the		the		True
    high		high		False
    tones		tone		False
    of		of		True
    the		the		True
    horn		horn		False
    the		the		True
    gold		gold		False
    ring		ring		False
    fits		fit		False
    only		only		True
    a		a		True
    pierced		pierce		False
    -		-		False
    ear		ear		False
    the		the		True
    old		old		False
    pan		pan		False
    was		be		True
    covered		cover		False
    with		with		True
    hard		hard		False
    fudge		fudge		False
    what		what		True
    's		be		True
    the		the		True
    log		log		False
    float		float		False
    in		in		True
    the		the		True
    wide		wide		False
    river		river		False
    the		the		True
    node		node		False
    on		on		True
    the		the		True
    stalk		stalk		False
    of		of		True
    wheat		wheat		False
    grew		grow		False
    daily		daily		False
    the		the		True
    Heap		Heap		False
    of		of		True
    fallen		fall		False
    leaves		leave		False
    was		be		True
    set		set		False
    on		on		True
    fire		fire		False
    right		right		False
    fast		fast		False
    if		if		True
    you		-PRON-		True
    want		want		False
    to		to		True
    finish		finish		False
    early		early		False
    his		-PRON-		True
    shirt		shirt		False
    was		be		True
    clean		clean		False
    but		but		True
    one		one		True
    button		button		False
    was		be		True
    gone		go		False
    the		the		True
    barrel		barrel		False
    of		of		True
    beer		beer		False
    was		be		True
    a		a		True
    brew		brew		False
    of		of		True
    malt		malt		False
    and		and		True
    hops		hop		False
    tin		tin		False
    cans		can		False
    are		be		True
    absent		absent		False
    from		from		True
    store		store		False
    shelves		shelf		False
    

**2.4b Resultado**   
Podemos observar el mismo proceso anterior analizando la información en español, sin embargo la traducción en este caso no es muy buena. Si observamos más en detalle el resultado de cada oración dependerá de la presición de la traducción ya que las palabras originales se encuentran en otro idioma. Sin embargo la tokenizacion la lematización y las stopwords son tratadas de la misma forma con un modelo en español. 


```python
doc2 = nlp_es(doc_es.text)
print("Español \n")
print(doc_es.text,"\n")
print(f"Token \t\tLemma \t\tStopword".format('Token', 'Lemma', 'Stopword'))
print("-"*40)
for token in doc2:
    print(f"{str(token)}\t\t{token.lemma_}\t\t{token.is_stop}")
```

    Español 
    
    el mudo amortiguado los tonos agudos del cuerno el anillo de oro se ajusta solo a una oreja perforada la sartén vieja estaba cubierta con dulce de azúcar duro lo que es el tronco flotante en el ancho río el nudo en el tallo de trigo crecía a diario el montón de hojas caídas se ponía en llamas rápidamente si quieres terminar temprano su camisa estaba limpia pero un botón no estaba el barril de cerveza era una infusión de malta y las latas de lúpulo están ausentes en los estantes de las tiendas 
    
    Token 		Lemma 		Stopword
    ----------------------------------------
    el		el		True
    mudo		mudar		False
    amortiguado		amortiguar		False
    los		lo		True
    tonos		tono		False
    agudos		agudo		False
    del		del		True
    cuerno		cuerno		False
    el		el		True
    anillo		anillar		False
    de		de		True
    oro		orar		False
    se		se		True
    ajusta		ajustar		False
    solo		solo		True
    a		a		False
    una		uno		True
    oreja		oreja		False
    perforada		perforar		False
    la		lo		True
    sartén		sartén		False
    vieja		viejo		False
    estaba		estar		True
    cubierta		cubrir		False
    con		con		True
    dulce		dulce		False
    de		de		True
    azúcar		azúcar		False
    duro		durar		False
    lo		el		True
    que		que		True
    es		ser		True
    el		el		True
    tronco		troncar		False
    flotante		flotante		False
    en		en		True
    el		el		True
    ancho		ancho		False
    río		reír		False
    el		el		True
    nudo		nudo		False
    en		en		True
    el		el		True
    tallo		tallar		False
    de		de		True
    trigo		trigo		False
    crecía		crecer		False
    a		a		False
    diario		diario		False
    el		el		True
    montón		montón		False
    de		de		True
    hojas		hoja		False
    caídas		caída		False
    se		se		True
    ponía		poner		False
    en		en		True
    llamas		llamar		False
    rápidamente		rápidamente		False
    si		si		True
    quieres		querer		False
    terminar		terminar		False
    temprano		temprano		True
    su		su		True
    camisa		camisa		False
    estaba		estar		True
    limpia		limpio		False
    pero		pero		True
    un		uno		True
    botón		botón		False
    no		no		True
    estaba		estar		True
    el		el		True
    barril		barril		False
    de		de		True
    cerveza		cerveza		False
    era		ser		True
    una		uno		True
    infusión		infusión		False
    de		de		True
    malta		malta		False
    y		y		False
    las		los		True
    latas		lato		False
    de		de		True
    lúpulo		lúpulo		False
    están		estar		True
    ausentes		ausente		False
    en		en		True
    los		lo		True
    estantes		estante		False
    de		de		True
    las		los		True
    tiendas		tienda		False
    

## 3.Conclusión


Con pequeñas lineas de código gracias a las librerías anteriores, podemos analizar mucha información y separarlas de acuerdo a nuestro target. La información resultante podría ser de gran utilidad ya que se podría transformar en algo de mucho valor y simplificar u ordenar como base para nuestra investigación o modelo predictivo para futuras desiciones o investigaciones mas profundas.    
Este proyecto es solo una introducción a lo que el **PLN** puede ofrecernos. 

## 4.Recursos
[How Speech Recognition Works](https://realpython.com/python-speech-recognition/#how-speech-recognition-works-an-overview)     
[Traduciendo texto en python](https://programacionpython80889555.wordpress.com/2020/06/02/traduciendo-texto-en-python-con-googletrans/)   
[ Open Speech Repository](http://www.voiptroubleshooter.com/open_speech/american.html)      
[speech_recognition](https://pypi.org/project/SpeechRecognition/)  
[Intro to NPL](https://www.kaggle.com/matleonard/intro-to-nlp)  
[googletrans](https://pypi.org/project/googletrans/)   
[StopWords](https://luisolavea.xyz/stopwords/)  
[spacy](https://spacy.io/usage)    
